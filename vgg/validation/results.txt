layer1: 256, layer2: 256, Dropout: 0.1, Activation: relu
Validation accuracy = [0.75, 0.8111111, 0.81666666, 0.7777778, 0.8333333, 0.82222223, 0.8277778, 0.7777778, 0.8055556, 0.8055556, 0.82222223, 0.73888886, 0.74444443, 0.8277778, 0.81666666, 0.8388889, 0.8388889, 0.84444445, 0.82222223, 0.81666666, 0.85, 0.84444445, 0.8388889, 0.8611111, 0.81666666, 0.8666667, 0.84444445, 0.8111111, 0.8333333, 0.8388889]
----------------------
Validation loss = [8.935882536570231, 4.954110791948106, 5.937970330980089, 10.439290534125433, 6.819403429800069, 13.440684056944159, 14.176832665337457, 14.281335269080268, 12.437300539678995, 12.589506181081136, 12.751617092556424, 18.639402235878837, 23.54231622483995, 20.770088725619846, 23.830460584660372, 14.877994560864236, 16.038092042298782, 17.540854410330454, 23.305120764838325, 29.94037611219618, 21.238169627719454, 27.116773234473335, 21.582433936988895, 22.912618605295815, 36.70013156467014, 19.09796412785848, 21.801344113879733, 21.915662084685433, 23.708933599789937, 22.216975190904407]
----------------------
----------------------

layer1: 256, layer2: 256, Dropout: 0.1, Activation: tanh
Validation accuracy = [0.60555553, 0.6, 0.65555555, 0.50555557, 0.67777777, 0.68333334, 0.62222224, 0.6166667, 0.65, 0.60555553, 0.43333334, 0.6388889, 0.6111111, 0.5888889, 0.5833333, 0.5388889, 0.60555553, 0.62222224, 0.57222223, 0.6388889, 0.68333334, 0.6388889, 0.62777776, 0.6611111, 0.6166667, 0.64444447, 0.6, 0.6166667, 0.64444447, 0.62222224]
----------------------
Validation loss = [1.0675921890470716, 0.9859485043419732, 0.9563527372148302, 0.93303472465939, 0.9377430597941081, 0.8797560148768955, 1.0225271383921306, 1.0189474158816867, 0.9938101980421278, 1.030164771609836, 1.118888881471422, 1.0948177271419102, 1.0038342740800645, 1.1545747756958007, 1.1233457777235243, 1.2364747683207193, 1.0496583037906222, 1.0063019010755752, 1.1981412808100382, 1.0564231395721435, 0.9759184148576524, 1.0644234524832832, 1.0158924288219875, 1.0189825031492445, 1.0138483471340602, 1.0051576442188688, 1.0381457249323527, 1.0331057826677958, 1.0428518719143338, 1.013204558690389]
----------------------
----------------------

layer1: 256, layer2: 256, Dropout: 0.2, Activation: relu
Validation accuracy = [0.76111114, 0.75, 0.79444444, 0.8277778, 0.7888889, 0.8055556, 0.8, 0.73333335, 0.75, 0.79444444, 0.82222223, 0.79444444, 0.8277778, 0.75, 0.7888889, 0.8, 0.81666666, 0.79444444, 0.8055556, 0.81666666, 0.8111111, 0.79444444, 0.81666666, 0.7777778, 0.79444444, 0.7777778, 0.7777778, 0.78333336, 0.81666666, 0.8]
----------------------
Validation loss = [6.342172945870294, 4.660368491543664, 5.518966385256499, 4.780646673838297, 9.307645670986838, 8.549255153205658, 10.63812103735076, 9.37897703382704, 11.60190667039844, 16.930675082736546, 10.770284995105127, 12.237919489542643, 12.222780394601998, 11.321091906229656, 9.968264071146647, 9.702097373538548, 9.08920382393731, 12.16616544855965, 12.225618598196242, 10.995934488350112, 11.591615502039591, 21.732072741455504, 14.21349585056305, 17.06860441631741, 11.641374831729465, 16.621065198050605, 11.781595739391115, 15.978342659466175, 20.709719551934135, 15.60126830206977]
----------------------
----------------------

layer1: 256, layer2: 256, Dropout: 0.2, Activation: tanh
Validation accuracy = [0.4, 0.53333336, 0.60555553, 0.5611111, 0.5833333, 0.60555553, 0.5833333, 0.5611111, 0.5833333, 0.60555553, 0.6, 0.6388889, 0.59444445, 0.5833333, 0.6333333, 0.59444445, 0.6333333, 0.56666666, 0.64444447, 0.56666666, 0.6111111, 0.62222224, 0.51111114, 0.62222224, 0.5833333, 0.62777776, 0.6166667, 0.60555553, 0.62222224, 0.6166667]
----------------------
Validation loss = [1.3003638585408528, 1.297250713242425, 1.1126499970753987, 1.1823399543762207, 1.054754258526696, 1.154418569140964, 0.9880216836929321, 1.157623709572686, 1.1456818461418152, 1.0056758642196655, 1.0217827412817213, 1.0330450693766275, 1.0560974730385675, 1.065238152609931, 1.0165044082535637, 0.9898746516969469, 1.000305880440606, 1.0933544158935546, 1.0399482938978406, 1.1149606267611185, 1.000598598851098, 1.006522035598755, 1.063797206348843, 1.0643082539240518, 1.0909704009691874, 0.994962109459771, 1.0381493435965643, 1.0262068801456028, 1.0396027459038628, 0.9987872335645888]
----------------------
----------------------

layer1: 256, layer2: 256, Dropout: 0.3, Activation: relu
Validation accuracy = [0.75, 0.76111114, 0.8277778, 0.74444443, 0.78333336, 0.7722222, 0.8277778, 0.76666665, 0.75555557, 0.8, 0.79444444, 0.7777778, 0.73888886, 0.7222222, 0.73888886, 0.73333335, 0.76111114, 0.78333336, 0.75555557, 0.7722222, 0.76111114, 0.78333336, 0.76111114, 0.7777778, 0.73888886, 0.74444443, 0.75555557, 0.73888886, 0.75, 0.71666664]
----------------------
Validation loss = [8.358040497803854, 2.7175366341045852, 6.024045946945747, 7.343587191899617, 5.50447187423706, 5.8423271656036375, 3.4099317531308366, 3.6363474236594304, 5.555003778802024, 3.7580653137630886, 5.037338489956326, 2.903253738085429, 3.4110663309693336, 4.6645634200837875, 5.300322874387105, 4.899732992384169, 4.570360392994351, 4.249042448070314, 7.76803138057114, 3.6955284807417126, 3.3297813481754726, 3.846703592936198, 7.5832889397939045, 6.556267611185709, 4.86843855910831, 5.850474931796392, 4.4350045363108315, 4.034107367197673, 3.5552108499738906, 2.4813349511888294]
----------------------
----------------------

layer1: 256, layer2: 256, Dropout: 0.3, Activation: tanh
Validation accuracy = [0.6388889, 0.6333333, 0.6333333, 0.6722222, 0.60555553, 0.6611111, 0.6166667, 0.6111111, 0.65555555, 0.6333333, 0.64444447, 0.5888889, 0.65, 0.64444447, 0.59444445, 0.56666666, 0.62777776, 0.6111111, 0.5888889, 0.5833333, 0.5888889, 0.5777778, 0.57222223, 0.6, 0.60555553, 0.62777776, 0.6166667, 0.57222223, 0.6333333, 0.5888889]
----------------------
Validation loss = [0.951730924182468, 1.0250765641530355, 0.9744743678304885, 0.9170544412400987, 1.0084146903620825, 0.8673946062723795, 0.9318031814363268, 0.9008408811357286, 1.0062732252809736, 0.8981414066420661, 0.9349250078201294, 0.9629901435640124, 0.8813107556766934, 0.9015827655792237, 0.8961665232976278, 1.0245296133889092, 0.9903020752800835, 1.0611441983116998, 1.0325590623749628, 1.0817989773220487, 1.041316956281662, 1.0847344742880927, 1.0709447893831465, 1.0217764033211603, 1.0302529288662805, 0.944927716255188, 0.9789556635750665, 1.0745672384897869, 0.9461537745263842, 1.0604363520940145]
----------------------
----------------------

layer1: 256, layer2: 256, Dropout: 0.4, Activation: relu
Validation accuracy = [0.71666664, 0.6888889, 0.68333334, 0.6944444, 0.6388889, 0.62777776, 0.59444445, 0.6111111, 0.6166667, 0.6111111, 0.6333333, 0.6333333, 0.62222224, 0.6333333, 0.62222224, 0.6166667, 0.6388889, 0.6111111, 0.62777776, 0.62777776, 0.62777776, 0.6166667, 0.6166667, 0.6166667, 0.6166667, 0.6166667, 0.62222224, 0.62222224, 0.62222224, 0.62222224]
----------------------
Validation loss = [5.596693801879883, 4.670989614062839, 2.3487227651807996, 1.7564714405271742, 2.514699247148302, 2.2757267978456284, 3.0728732056087917, 3.6944590356614855, 2.77446957760387, 1.9203682310051389, 1.7848897324668036, 1.7547410832511054, 2.2614762253231473, 1.72288592060407, 1.9498998959859213, 1.3629648553000555, 1.5362670275900099, 1.5512435608439976, 1.9694389820098877, 2.199601573414273, 2.624454445309109, 1.2923701604207356, 1.2801682233810425, 3.1100900616910723, 1.6062594307793512, 1.7633369339836968, 2.3000859141349794, 2.39847920205858, 2.222636021508111, 3.602999308374193]
----------------------
----------------------

layer1: 256, layer2: 256, Dropout: 0.4, Activation: tanh
Validation accuracy = [0.5611111, 0.6111111, 0.5777778, 0.5888889, 0.5833333, 0.5611111, 0.60555553, 0.6666667, 0.5611111, 0.5611111, 0.5611111, 0.5611111, 0.5611111, 0.5777778, 0.5611111, 0.5611111, 0.5611111, 0.5611111, 0.5611111, 0.5611111, 0.5611111, 0.5611111, 0.5611111, 0.5611111, 0.5611111, 0.5611111, 0.5611111, 0.5611111, 0.5611111, 0.5611111]
----------------------
Validation loss = [1.1539043366909028, 1.1488393094804552, 1.1480416350894505, 1.1100457959704928, 1.1228399170769585, 1.073029637336731, 1.0110347588857016, 1.013279758559333, 1.1327600611580744, 1.1272594743304782, 1.1201770861943563, 1.2236978001064724, 1.1151815917756822, 1.2109222451845805, 1.1947584443622166, 1.0843617187605963, 1.1162829054726495, 1.1242609765794542, 1.2181849161783853, 1.1253350522783068, 1.122931374443902, 1.0972212923897637, 1.1045860767364502, 1.1213511493470933, 1.136362659931183, 1.147929679022895, 1.1853479146957397, 1.1426782025231255, 1.1976557519700792, 1.1553661968972948]
----------------------
----------------------

layer1: 256, layer2: 256, Dropout: 0.5, Activation: relu
Validation accuracy = [0.76666665, 0.6388889, 0.68333334, 0.7, 0.6333333, 0.6888889, 0.6111111, 0.6333333, 0.62777776, 0.6, 0.65555555, 0.62222224, 0.6111111, 0.6166667, 0.6111111, 0.6111111, 0.60555553, 0.60555553, 0.6, 0.60555553, 0.60555553, 0.6111111, 0.6, 0.60555553, 0.60555553, 0.5611111, 0.5777778, 0.5777778, 0.5777778, 0.5777778]
----------------------
Validation loss = [7.449297216865752, 3.3940357155270044, 1.7753113680415684, 2.873848231633504, 2.016473012500339, 1.04927486843533, 1.4971619923909505, 1.2595794995625813, 1.0461056338416206, 1.1366610262129042, 1.4571336057451036, 1.6562168134583368, 1.2464500427246095, 1.1749998013178506, 1.199239608976576, 1.3764687564637925, 1.1686339457829793, 1.5651203367445203, 1.4671927716996935, 1.4894092877705891, 1.25871438715193, 1.375138356950548, 1.3478016588422987, 1.115416399637858, 1.21722741789288, 1.8415627929899427, 1.7680237452189127, 1.7002031882603963, 1.951860769589742, 1.523428397708469]
----------------------
----------------------

